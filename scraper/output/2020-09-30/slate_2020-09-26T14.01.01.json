{"authors": ["S.B. Divya"], "body": "An expert on machine learning responds to Yudhanjaya Wijeratne\u2019s \u201cThe State Machine.\u201d\n\nThe world of software has a long-held, pernicious myth that a system built from digital logic cannot have biases. A piece of code functions as an object of pure reason, devoid of emotion and all the messiness that entails. From this thesis flows an idea that has gained increasing traction in the worlds of both technology and science fiction: a perfectly rational system of governance built upon artificial intelligence. If software can\u2019t lie, and data can\u2019t inherently be wrong, then what could be more equitable and efficient than the rule of a machine-driven system?\n\nIn \u201cThe State Machine,\u201d Yudhanjaya Wijeratne explores a possible future where this concept has become reality. He takes the idea of A.I. government a step further by making it highly dynamic, with regular changes to the constitution and legal framework. Given how much of our lives are now in the hands of massive software applications\u2014communications, banking, health care\u2014I can see large swaths of humanity choosing to live under an A.I.-based government, rather than under human politicians, in hopes of more equitable treatment under the law and less overall corruption. It could happen incrementally, as it does in this story, so we go along with it, until one day a sizable portion of the world\u2019s population finds itself living this way. You have only to look at Facebook, which now has 2.7 billion monthly active users (more than one-third of the world!), for a very real example.\n\nBiases and emotions are built into software systems by the fallible and illogical people who design them.\n\nWijeratne\u2019s fictional State Machine seems like a fairly benevolent overlord\u2014more Big Mother than Big Brother. It\u2019s attuned to the emotional and physical well-being of its citizens through a distributed network of real-world extensions (the emoji robots). Some of us might call them spies, but they\u2019re only there for our best interests. The State Machine hands out flowers at first, and more strict measures when necessary, but it tries to maintain a \u201cdelicate symbiosis between machine input and well-intentioned social campaigns, setting forth in hard code a law that people who suffer must be taken care of.\u201d It expresses neither fascist paternalism nor the blanket kindergarten rules of a nanny state. It\u2019s maternal\u2014nurturing but firm, like the Giving Tree, with an attempt to maintain healthy boundaries. Doesn\u2019t sound so bad, right?\n\nThis dream crashes into reality via a basic fact: Biases and emotions are built into software systems by the fallible and illogical people who design them. We see this on a regular basis in the world of machine intelligence today. Whether the system is using supervised learning (where a human shows the machine what is right and wrong) or unsupervised learning (where the machine tries to categorize right from wrong on its own until the human says it\u2019s done), the information provided to the machine must pass through a living gatekeeper. Sometimes that means the data fed to the machine is incomplete, as with recent problems in facial recognition. Sometimes it\u2019s erroneous or lacks context, like the fun examples by Janelle Shane. Sometimes it\u2019s a product of what that human expects or desires to see as a conclusion, as with racial biases reinforced in policing and lending. Artificial intelligence (much like fiction) reveals to us the inherent truths of our lives, not some greater glimpse of reality.\n\nSo what of the later stages of the State Machine as posited in this story? What happens if the software reaches a state of self-sustaining complexity such that humans only think they\u2019re in the loop? Will that solve the problem of systematic bias? I would argue not. People, being the perverse creatures of willfulness that we are, would find a way to game the system. The historian protagonist of this story isn\u2019t that type of person, but I\u2019m sure the society he inhabits will have some. Those are the ones who will frustrate \u201cBig Mother\u201d and drive it to apply suboptimal or even harmful amendments to its laws. We\u2019d end up facing the same problems we have with democracy today: insufficient protection for minority rights, susceptibility to demagogues, and lack of long-term thinking, to name a few.\n\nOne of the greatest challenges of raising a child is maintaining a balance between authority and compassion. Every parent exists somewhere on this spectrum, but I\u2019m not sure there\u2019s an optimal location, not for one parent and one child, not even for one given moment. Being human, we\u2019re always searching for a perfect and guaranteed solution to life, but being inhabitants of a massively chaotic world, we\u2019re never going to find it, and we don\u2019t like to think of ourselves as predictable. I think the State Machine acknowledges this when it references the sensitivity to initial conditions. A sufficiently self-aware entity, whether human or artificial, is going to recognize its limitations. In this story, the State Machine realizes that it isn\u2019t omniscient, that it won\u2019t always make the best choices, which raises the question: Why is it a preferable way to govern ourselves?\n\nAn artificial intelligence that can truly understand our behavior will be no better than us at dealing with humanity\u2019s challenges. It\u2019s not God in the machine. It\u2019s just another flawed entity, doing its best with a given set of goals and circumstances. Right now we treat A.I.s like children, teaching them right from wrong. It could be that one day they\u2019ll leapfrog us, and the children will become the parents. Most likely, our relationship with them will be as fraught as any intergenerational one. But what happens if parents never age, never grow senile, and never make room for new life? No matter how benevolent the caretaker, won\u2019t that create a stagnant society?\n\nGrowing up means taking responsibility for ourselves, including ownership of our mistakes. Big Mother will have to allow us to manage our own lives at some point\u2014otherwise we risk smothering ourselves into a state of perpetual immaturity. We might need a machine intelligence to help us attain the adulthood of our civilization, but as with Wittgenstein\u2019s proverbial ladder, we\u2019ll need to throw it away in order to embark on the next stage of our growth.\n\nFuture Tense is a partnership of Slate, New America, and Arizona State University that examines emerging technologies, public policy, and society.", "current_date": "2020-09-30 18:58:30.697018", "publish_date": "2020-09-26", "publish_datetime": "2020-09-26 14:01:01.257000+00:00", "publish_time": "14:01:01", "source": "slate", "title": "An expert on machine learning responds to Yudhanjaya Wijeratne\u2019s \u201cThe State Machine.\u201d", "topics": ["learning", "human", "yudhanjaya", "machine", "world", "wrong", "system", "right", "software", "intelligence", "state", "built", "expert", "responds", "wijeratnes"]}